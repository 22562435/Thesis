---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Thesis Proposal: Machine Learning and Volatility Models "
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
# Thesis_FP: TRUE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Some Guy}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# #Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Liam Andrew Beattie"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Stellenbosch University, South Africa" # First Author's Affiliation
Email1: "22562435\\@sun.ac.za"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
   
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!

# Lets load in example data, and see how this can be stored and later called from your 'data' folder.
if(!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)


```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction \label{Introduction}


Here are the papers I intend to read and give a brief summary of them:

@GUNNARSSON2024103221[p. 33]
@Horvath2021DeepVol
@Petrozziello2022DeepVol
@Wu2024InvestableAI
@Wu2025CrossAssetVol
@ZENG2019376
@Zhang2023VolForecastML


[@ZENG2019376 \& @Zhang2023VolForecastML]



# Data  {-}




To write a comprehensive, focused quantitative econometric paper on machine learning and volatility models with less emphasis on an extensive literature review, you should prioritize a **clearly defined and narrow research question** and a **rigorous quantitative analysis** directly addressing that question. Hereâ€™s how you can structure your paper, drawing on the provided sources:

**I. Introduction and Focused Research Question:**

*   Start with a concise introduction that immediately highlights the specific gap you are addressing in the literature or a particular problem you are investigating.
*   **Clearly state your focused research question(s)**. For instance, instead of broadly investigating if ML can forecast volatility better than traditional models, you might focus on:
    *   The performance of a specific novel ML architecture (e.g., an attention-based deep learning model) in forecasting the implied volatility of a particular asset class (e.g., S&P 500 options) compared to a specific benchmark (e.g., a specific GARCH extension or HAR model).
    *   The impact of a specific type of high-frequency intraday data (e.g., order book data, transaction volume) as features in an ML model for short-term realized volatility forecasting for a specific set of stocks.
    *   The effectiveness of a particular XAI technique (e.g., SHAP values) in interpreting the predictions of a specific ML model applied to implied volatility surface modeling.
    *   The economic value (e.g., through backtesting trading strategies) of volatility forecasts from a specific ML model compared to a standard econometric model for a defined set of assets.
*   Briefly mention the contribution of your focused study to the existing literature without an exhaustive review at this stage. You can refer to recent reviews to justify the relevance of your specific angle.
*   Outline the structure of your paper.

**II. Data:**

*   Provide a detailed description of the specific dataset(s) you will use.
*   Clearly define your volatility measure (e.g., realized volatility calculated from high-frequency returns, implied volatility from option prices, or volatility indices like VIX).
*   Specify the asset class(es), time period, and sampling frequency. If using high-frequency data, explain the cleaning and aggregation methods.
*   Describe the predictor variables you will use, justifying their selection based on previous findings (cite specific papers from the existing literature concisely) or theoretical arguments. If using exogenous data, clearly state its source and frequency.

**III. Methodology:**

*   **Clearly and concisely present the econometric and machine learning models** you will employ. Focus on the mathematical specification of the models.
    *   For ML models, describe the architecture, activation functions, optimization algorithm (e.g., Adam), and hyperparameter tuning process (e.g., cross-validation).
    *   For benchmark econometric models (e.g., GARCH, HAR), provide their standard formulations.
*   Explain your chosen training scheme (e.g., single asset, pooling data) and out-of-sample testing procedure (e.g., rolling window).
*   If applicable, describe any feature engineering techniques or data transformations you will use.
*   If your focus includes explainability, detail the XAI methods you will apply.
*   If you are investigating computational aspects, describe the hardware or software used (e.g., FPGA technology).

**IV. Evaluation Metrics:**

*   Specify the **quantitative evaluation metrics** you will use to compare the forecasting performance of your models. These could include statistical measures like Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE), Quasi-Likelihood (QLIKE), and statistical tests for predictive accuracy like the Diebold-Mariano (DM) test.
*   If your research question involves economic significance, clearly outline how you will evaluate the models from an economic point of view (e.g., through backtesting trading strategies, Value-at-Risk (VaR) analysis).

**V. Empirical Results and Discussion:**

*   Present your quantitative results in a clear and organized manner using tables and figures.
*   **Focus your discussion directly on answering your stated research question(s)** based on the empirical evidence.
*   Compare the performance of your chosen ML model(s) against the benchmark econometric model(s) using the selected evaluation metrics.
*   Analyze the statistical significance of any performance differences (e.g., using DM tests).
*   Discuss the implications of your findings in the context of the specific niche you are investigating. Briefly connect your results to the broader literature, highlighting how your focused study contributes or contrasts with existing findings. You can be more selective in the literature you discuss here, focusing on the most directly relevant studies.
*   If applicable, interpret the results of your XAI analysis, explaining which features are most important for your ML model's predictions.
*   If you conducted an economic evaluation, discuss the practical implications of your findings.

**VI. Conclusion and Future Work:**

*   Summarize your main quantitative findings and directly address your research question(s).
*   Briefly reiterate the contribution of your focused study.
*   Suggest specific avenues for future research that build directly on your findings and the limitations of your study.

**Strategies for Reducing Literature Review:**

*   **Target a Very Specific Gap:** Instead of reviewing the entire landscape of ML in volatility, focus on a very narrow sub-topic where the existing literature is limited or where a specific technique has not been thoroughly explored (e.g., the application of a particular deep learning architecture to a niche market). The literature review can then be more concentrated on the immediate context of your research question.
*   **Build Upon a Recent Survey:** Since comprehensive literature reviews exist, you can briefly summarize the state of the art based on these reviews and then immediately narrow down to the specific issue your paper addresses.
*   **Focus on Methodological Innovation or Application:** If your paper introduces a novel ML technique or applies an existing one to a new and underexplored area of volatility modeling, the literature review can be more focused on the methodological background and the specific context of your application, rather than a broad overview of all volatility models or all ML techniques.
*   **Assume Familiarity with Standard Models:** For well-established econometric models (like GARCH) and common ML algorithms (like basic neural networks), you can often provide a brief description and cite seminal works without an extensive historical review.

By adopting a focused research question and prioritizing a rigorous quantitative analysis, you can write a comprehensive and valuable econometric paper on machine learning and volatility models with a less extensive literature review. The key is to be precise in your question, thorough in your methodology and evaluation, and direct in your discussion of the results in relation to your specific focus.
